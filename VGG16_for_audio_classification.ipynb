{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa opencv-python numpy matplotlib tensorflow"
      ],
      "metadata": {
        "id": "2FkwHHWctazq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload your zip file (this will open a file dialog)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the uploaded zip file\n",
        "for filename in uploaded.keys():\n",
        "    zip_path = f\"/content/{filename}\"\n",
        "    extract_path = \"/content/audio_data\"\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "# Show top-level folders inside the extracted path\n",
        "print(\"Extracted folders in /content/audio_data:\")\n",
        "print(os.listdir(extract_path))"
      ],
      "metadata": {
        "id": "DjbFlhV5uCZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "uploaded = files.upload()  # Upload your dataset.zip again\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('/content/dataset')\n",
        "        print(f\"{filename} extracted to /content/dataset\")\n"
      ],
      "metadata": {
        "id": "JQs9f2Ucx7wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content/audio_data\"):\n",
        "    level = root.replace(\"/content/audio_data\", \"\").count(os.sep)\n",
        "    indent = \" \" * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    for f in dirs:\n",
        "        print(f\"{indent}    {f}/\")"
      ],
      "metadata": {
        "id": "F_2wR-fnBMuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List contents of /content to see where files might have been placed\n",
        "print(\"Contents of /content:\")\n",
        "print(os.listdir(\"/content\"))"
      ],
      "metadata": {
        "id": "JqLu4G_qCFjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_path = \"/content/Three-classes-classify-20250512T134602Z-1-001.zip\"\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# List contents of extracted folder to check if the classes are there\n",
        "print(\"Contents of extracted dataset:\")\n",
        "print(os.listdir(extract_path))"
      ],
      "metadata": {
        "id": "miwxtCm9CRf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents inside the Three-classes-classify folder\n",
        "extracted_folder = \"/content/dataset/Three-classes-classify\"\n",
        "print(\"Contents of /content/dataset/Three-classes-classify:\")\n",
        "print(os.listdir(extracted_folder))"
      ],
      "metadata": {
        "id": "tm9GgLSZCeof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents inside the nested Three-classes-classify folder\n",
        "nested_folder = \"/content/dataset/Three-classes-classify/Three-classes-classify\"\n",
        "print(\"Contents of /content/dataset/Three-classes-classify/Three-classes-classify:\")\n",
        "print(os.listdir(nested_folder))"
      ],
      "metadata": {
        "id": "VXiD5bS9CnsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define source and destination directories\n",
        "source_dir = \"/content/dataset/Three-classes-classify/Three-classes-classify\"\n",
        "dest_dir = \"/content/audio_data\"\n",
        "\n",
        "# Move class folders to audio_data\n",
        "for folder_name in os.listdir(source_dir):\n",
        "    folder_path = os.path.join(source_dir, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        shutil.move(folder_path, dest_dir)\n",
        "\n",
        "# List contents of /content/audio_data to confirm move\n",
        "print(\"Contents of /content/audio_data after move:\")\n",
        "print(os.listdir(dest_dir))"
      ],
      "metadata": {
        "id": "IEwcni3LCxju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for audio files in each class folder\n",
        "for folder_name in os.listdir(\"/content/audio_data\"):\n",
        "    folder_path = os.path.join(\"/content/audio_data\", folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(f\"Files in {folder_name}:\")\n",
        "        print(os.listdir(folder_path)[:5])  # Print first 5 files for each class"
      ],
      "metadata": {
        "id": "aaVigjXYC503"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Function to convert audio file to spectrogram\n",
        "def audio_to_spectrogram(audio_path, image_path):\n",
        "    # Load audio file\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # Generate spectrogram\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "\n",
        "    # Plot the spectrogram\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save spectrogram as image\n",
        "    plt.savefig(image_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "# Directory to save spectrograms\n",
        "spectrogram_dir = '/content/spectrograms'\n",
        "os.makedirs(spectrogram_dir, exist_ok=True)\n",
        "\n",
        "# Loop through class folders and process audio files\n",
        "for folder_name in os.listdir(\"/content/audio_data\"):\n",
        "    folder_path = os.path.join(\"/content/audio_data\", folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Create a sub-folder for each class in spectrogram_dir\n",
        "        class_spectrogram_dir = os.path.join(spectrogram_dir, folder_name)\n",
        "        os.makedirs(class_spectrogram_dir, exist_ok=True)\n",
        "\n",
        "        # Process each audio file in the class folder\n",
        "        for audio_file in os.listdir(folder_path):\n",
        "            if audio_file.endswith(\".wav\"):\n",
        "                audio_path = os.path.join(folder_path, audio_file)\n",
        "                spectrogram_path = os.path.join(class_spectrogram_dir, audio_file.replace(\".wav\", \".png\"))\n",
        "                audio_to_spectrogram(audio_path, spectrogram_path)\n",
        "\n",
        "print(\"Spectrogram generation complete!\")"
      ],
      "metadata": {
        "id": "dfJHtA7-DG3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Directory where the spectrograms are stored\n",
        "spectrogram_dir = '/content/spectrograms'\n",
        "\n",
        "# Create directories for training and validation sets\n",
        "train_dir = '/content/spectrograms/train'\n",
        "val_dir = '/content/spectrograms/val'\n",
        "\n",
        "# Create the train and validation directories if they do not exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Create subdirectories for each class within train and validation directories\n",
        "for class_name in ['Human-Voice', 'Human-Voicemail', 'Machine-Voicemail']:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "for class_name in ['Human-Voice', 'Human-Voicemail', 'Machine-Voicemail']:\n",
        "    class_path = os.path.join(spectrogram_dir, class_name)\n",
        "    files = os.listdir(class_path)\n",
        "\n",
        "    # Split the files into train and validation sets\n",
        "    train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Move files to respective directories\n",
        "    for file in train_files:\n",
        "        shutil.move(os.path.join(class_path, file), os.path.join(train_dir, class_name, file))\n",
        "\n",
        "    for file in val_files:\n",
        "        shutil.move(os.path.join(class_path, file), os.path.join(val_dir, class_name, file))\n",
        "\n",
        "# Check the new directory structure\n",
        "print(f\"Train directory: {os.listdir(train_dir)}\")\n",
        "print(f\"Validation directory: {os.listdir(val_dir)}\")"
      ],
      "metadata": {
        "id": "G3KcC0bSEsIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Set image size (VGG16 expects 224x224 input size)\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Create an ImageDataGenerator for loading and augmenting images\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Path to the spectrogram directory\n",
        "spectrogram_dir = '/content/spectrograms'\n",
        "\n",
        "# Prepare the image dataset using flow_from_directory\n",
        "train_data_gen = datagen.flow_from_directory(\n",
        "    spectrogram_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "# train_data_gen already takes care of shuffling, we just need to specify validation split\n",
        "val_data_gen = datagen.flow_from_directory(\n",
        "    spectrogram_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(\"Data preparation complete!\")"
      ],
      "metadata": {
        "id": "A_PPbBMzEb6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define train and validation directories\n",
        "train_dir = '/content/spectrograms/train'\n",
        "val_dir = '/content/spectrograms/val'\n",
        "\n",
        "# Check the contents of each class subdirectory in train and validation directories\n",
        "for dataset_dir, dataset_name in zip([train_dir, val_dir], [\"Train\", \"Validation\"]):\n",
        "    print(f\"\\n{dataset_name} Set:\")\n",
        "    for class_name in ['Human-Voice', 'Human-Voicemail', 'Machine-Voicemail']:\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        if os.path.exists(class_dir):\n",
        "            print(f\"{class_name}: {len(os.listdir(class_dir))} files\")\n",
        "        else:\n",
        "            print(f\"{class_name}: Directory does not exist\")"
      ],
      "metadata": {
        "id": "sKnZDkBGE9Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/spectrograms/train',\n",
        "    target_size=(224, 224),  # Resize images to VGG16 input size\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # We have 3 classes\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/spectrograms/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "0DkVjbED3naA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load VGG16 model with pre-trained weights (exclude top layer)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers to prevent training during initial fine-tuning\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom top layers for our specific problem\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # 3 output classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10,  # Adjust epochs as needed\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // val_generator.batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "2vhUW23u0ncc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "id": "9gHUIJRHwJ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on new spectrogram images\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load a new image for prediction\n",
        "img_path = '/content/20250422-211509-17348559018.png'  # Replace with the path of the new image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0  # Rescale the image\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make prediction\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Map prediction to class names\n",
        "class_names = ['Human-Voice', 'Human-Voicemail', 'Machine-Voicemail']\n",
        "print(f\"Predicted Class: {class_names[predicted_class[0]]}\")"
      ],
      "metadata": {
        "id": "iIANMQT2Gdhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}